{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "emotion_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "T93MR4LyHf6L",
        "colab_type": "code",
        "outputId": "9091cbc0-1e13-4850-f5e0-3719415899dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Importing all the required packages.\n",
        "\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn import decomposition, ensemble\n",
        "\n",
        "import pandas, xgboost, numpy, textblob, string\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import layers, models, optimizers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ8tOmBLIGCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('train + dev.txt', 'r') as f:\n",
        "  data = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRKahHhlIe25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('test.txt', 'r') as f:\n",
        "  test_data = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu6kgHytJusm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels,texts = [],[]\n",
        "for i,line in enumerate(data.split(\"\\n\")):\n",
        "  content = line.split()\n",
        "  labels.append(content[-1])\n",
        "  texts.append(\" \".join(content[1:-1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzzHI8ZOIo-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels,test_texts = [],[]\n",
        "for j,row in enumerate(test_data.split(\"\\n\")):\n",
        "  content = row.split()\n",
        "  test_labels.append(content[-1])\n",
        "  test_texts.append(\" \".join(content[1:-1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj2T4sRmI3rX",
        "colab_type": "code",
        "outputId": "b0cb5493-ae15-48f6-d54d-115d88aaba22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(test_texts[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hmm What does your bio mean? I donâ€™t have any bio\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAdOamWzKHrn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a dataframe using texts and lables\n",
        "trainDF = pandas.DataFrame()\n",
        "trainDF['text'] = texts\n",
        "trainDF['label'] = labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nc8zxzBKHgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a dataframe using texts and lables for test data\n",
        "testDF = pandas.DataFrame()\n",
        "testDF['test_text'] = test_texts\n",
        "testDF['test_label'] = test_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYLj5G-dJ8Si",
        "colab_type": "code",
        "outputId": "27f3b537-050c-4142-b097-a5968aaf9886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(type(trainDF['text']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJdM-7YkKI8l",
        "colab_type": "code",
        "outputId": "d02aa7c7-f73a-4dda-a48e-b81150342cb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(labels[26])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sad\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHDPcZZVKLOp",
        "colab_type": "code",
        "outputId": "1a2166a5-b537-4346-ed18-036dfb6b82cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(labels[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "angry\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOiTLBaRKS_T",
        "colab_type": "code",
        "outputId": "d43ed689-92dc-470d-aabb-c253836e9162",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(texts[2])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "By by Google Chrome Where you live\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WODYyNDiKVt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split the dataset into training and validation datasets \n",
        "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'])\n",
        "\n",
        "# label encode the target variable \n",
        "encoder = preprocessing.LabelEncoder()\n",
        "train_y = encoder.fit_transform(train_y)\n",
        "valid_y = encoder.fit_transform(valid_y)\n",
        "test_y = encoder.fit_transform(testDF['test_label'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-n6ZHWBQs4s",
        "colab_type": "code",
        "outputId": "877efc53-7c92-44cb-db0e-2b393a78cc28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(type(train_y))\n",
        "print(type(test_y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jTW3iBMJoAV",
        "colab_type": "code",
        "outputId": "c7cb1ecc-252e-45ad-f33f-8c076fc97871",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(type(train_x))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4w3RQpNQ1-Y",
        "colab_type": "code",
        "outputId": "77040ad4-f6cf-40dd-9e1a-1e6ae22d7424",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(test_y[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbrLydJmz83t",
        "colab_type": "code",
        "outputId": "bca3391f-024c-47b1-e757-5b57c18b32ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(train_y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 2 3 ... 2 3 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BqecpvmKjP2",
        "colab_type": "code",
        "outputId": "f8ca059e-2a61-418c-a04e-a8e7de266650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(len(train_x))\n",
        "print(len(valid_x))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24686\n",
            "8229\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKo8smLTKo7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# word level tf-idf\n",
        "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
        "tfidf_vect.fit(trainDF['text'])\n",
        "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
        "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
        "\n",
        "# ngram level tf-idf \n",
        "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
        "tfidf_vect_ngram.fit(trainDF['text'])\n",
        "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
        "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n",
        "\n",
        "# characters level tf-idf\n",
        "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
        "tfidf_vect_ngram_chars.fit(trainDF['text'])\n",
        "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
        "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyK8MQvSbPiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a count vectorizer object \n",
        "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
        "count_vect.fit(trainDF['text'])\n",
        "\n",
        "# transform the training and validation data using count vectorizer object\n",
        "xtrain_count =  count_vect.transform(train_x)\n",
        "xvalid_count =  count_vect.transform(valid_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6UrvCiplFo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train a LDA Model\n",
        "lda_model = decomposition.LatentDirichletAllocation(n_components=20, learning_method='online', max_iter=20)\n",
        "X_topics = lda_model.fit_transform(xtrain_count)\n",
        "topic_word = lda_model.components_ \n",
        "vocab = count_vect.get_feature_names()\n",
        "\n",
        "# view the topic models\n",
        "n_top_words = 10\n",
        "topic_summaries = []\n",
        "for i, topic_dist in enumerate(topic_word):\n",
        "    topic_words = numpy.array(vocab)[numpy.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
        "    topic_summaries.append(' '.join(topic_words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpl8deqNn-DX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
        "    # fit the training dataset on the classifier\n",
        "    classifier.fit(feature_vector_train, label)\n",
        "    \n",
        "    # predict the labels on validation dataset\n",
        "    predictions = classifier.predict(feature_vector_valid)\n",
        "    \n",
        "    if is_neural_net:\n",
        "        predictions = predictions.argmax(axis=-1)\n",
        "    \n",
        "    return metrics.accuracy_score(predictions, valid_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNxUI0Y3ogui",
        "colab_type": "code",
        "outputId": "dbf0d641-95fe-48b2-a269-f4d0c5474959",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Naive Bayes on Count Vectors\n",
        "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count)\n",
        "print (\"NB, Count Vectors: \", accuracy)\n",
        "\n",
        "# Naive Bayes on Word Level TF IDF Vectors\n",
        "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
        "print (\"NB, WordLevel TF-IDF: \", accuracy)\n",
        "\n",
        "# Naive Bayes on Ngram Level TF IDF Vectors\n",
        "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
        "print (\"NB, N-Gram Vectors: \", accuracy)\n",
        "\n",
        "# Naive Bayes on Character Level TF IDF Vectors\n",
        "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
        "print (\"NB, CharLevel Vectors: \", accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NB, Count Vectors:  0.7375136711629603\n",
            "NB, WordLevel TF-IDF:  0.6756592538583059\n",
            "NB, N-Gram Vectors:  0.709928302345364\n",
            "NB, CharLevel Vectors:  0.707740916271722\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoI2iWAXv0KA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB().fit(xtrain_tfidf_ngram, train_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qTiwDOJEdEt",
        "colab_type": "code",
        "outputId": "5bfe0c2b-5e8c-4b6b-874d-f2c3d4721b48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# SVM implementation on Ngram\n",
        "accuracy = train_model(svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto'), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
        "print(\"SVM, N-Gram Vectors: \", accuracy)\n",
        "\n",
        "#SVM implementation on Count vectors\n",
        "accuracy = train_model(svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto'), xtrain_count, train_y, xvalid_count)\n",
        "print(\"SVM, Count Vectors: \", accuracy)\n",
        "\n",
        "#SVM on character level tf idfvectors\n",
        "accuracy = train_model(svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto'), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
        "print(\"SVM, CharLevel Vectors: \", accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM, N-Gram Vectors:  0.732895856118605\n",
            "SVM, Count Vectors:  0.7842994288491919\n",
            "SVM, CharLevel Vectors:  0.8121278405638596\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCqo2geXL9m-",
        "colab_type": "text"
      },
      "source": [
        "# **TEst DATA**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euppfsCNMI1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# characters level tf-idf\n",
        "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
        "tfidf_vect_ngram_chars.fit(trainDF['text'])\n",
        "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
        "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF9NHE3QP_K5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}